---
description: 介绍参数辨识与零空间的基本概念与联系
date: '2025-12-27'
author: 'pxx'
categories:
  - Optimal Control
published: true
column:
  name: 参数学习
---

# 参数辨识 & 参数学习

## 1. 引言

在控制与系统理论中，“参数辨识（parameter identification）”与“参数学习（parameter learning）”长期作为两个相关但并不等价的问题存在。二者在研究目标、理论假设以及评价标准上具有本质差异，而在近年来的数据驱动控制与闭环学习框架下，这种差异往往被弱化甚至混淆，有必要在一开始加以澄清。

**参数辨识（Identification）** 的核心目标是恢复系统的真实物理参数，其前提通常包括：

1. 系统模型结构已知且正确；
2. 可获得足够丰富的输入–输出数据（即满足持续激励条件）；
3. 参数具有唯一性或至少在某种等价意义下是可区分的。

在这一语境下，参数的“正确性”本身即是研究目标，辨识结果通常需要与物理意义或先验知识相一致，性能指标更多被视为验证辨识有效性的手段，而非最终目标。

**参数学习（Learning）** 并不以恢复真实物理参数为首要目标，而是直接面向性能层面的优化，例如跟踪误差、闭环稳定性或长期回报等指标。在这一框架下，参数仅作为实现性能目标的中间变量，其数值是否等于真实物理参数并非关键，甚至在很多情况下并不重要。只要闭环行为满足设计要求，参数处于某种“等价解”或“非真实解”往往是可以接受的。

需要强调的是，参数学习并非参数辨识的弱化版本或近似替代，而是在目标函数与评价准则上与参数辨识并列存在的另一类问题。随着闭环系统辨识、强化学习以及联合控制器–模型参数优化方法的发展，这两类问题在算法层面日益融合：同一套优化机制既在更新模型参数，又直接影响控制性能。然而，这种算法层面的融合并不意味着问题本质的消失，相反，正是由于目标函数与闭环结构的改变，传统参数辨识中的可辨识性问题与参数学习中的参数漂移现象才以更加复杂的形式显现出来。

在实际应用中，参数辨识与参数学习问题广泛存在于多个研究方向之中。例如，在自适应控制中，参数在线更新用于补偿未知动力学；在闭环系统辨识中，模型参数通过运行数据持续修正；在基于模型的强化学习中，系统模型与控制策略往往被同时学习；而在联合控制器–观测器–模型参数的自动调参框架中，参数学习直接嵌入闭环优化过程。这些场景共同的特点是：参数更新发生在闭环之中，其行为不仅受数据影响，也深刻依赖于控制器本身。

## 2. 可观性、可辨识性与信息结构

在讨论参数是否能够被“学到”之前，需要首先回答一个更基础的问题：**系统从数据中究竟能够提供哪些信息**。在控制理论中，这一问题通常分别通过“可观性（observability）”与“可辨识性（identifiability）”来刻画。二者在概念上密切相关，但关注的对象与结论层级并不相同，混淆二者往往会导致对参数学习结果的误判。

### 2.1 可观性 vs 可辨识性

**可观性（Observability）** 描述的是系统状态层面的信息可获取性，即：

> 在给定输入与输出测量的条件下，系统的内部状态是否可以被唯一确定。

对于线性时不变系统
$$
\dot{x} = A x + B u, \qquad y = C x,
$$
可观性由经典的可观性矩阵
$$
\mathcal{O} =
\begin{bmatrix}
C \\
CA \\
\vdots \\
CA^{n-1}
\end{bmatrix}
$$
的秩条件 $rank(\mathcal{O})=n$ 给出。

它是一个关于状态动力学与输出映射结构的问题，通常与参数取值无关或仅弱相关。对于非线性系统，可观性往往通过局部线性化、可观性秩条件或微分几何方法来分析。

**可辨识性（Identifiability）** 则关注参数层面的问题：

> 不同的参数取值是否会在输入–输出层面产生可区分的行为。

如果存在不同参数 $\theta_1 , \theta_2$，却对所有允许的输入产生相同的输出响应，则这些参数在该实验或运行条件下是不可辨识的。可辨识性本质上是一个关于**参数等价类**的问题，而非单纯的估计精度问题。

二者的关键区别可以总结为：

- 可观性关注“**状态能否被看见**”；
- 可辨识性关注“**参数能否被区分**”。

二者之间并不存在简单的蕴含关系。一个系统可以在状态层面完全可观，但在参数层面仍然不可辨识；反之，在某些受限模型下，即便状态不可完全重构，某些参数仍可能通过输出统计特性被间接辨识。

因此，可辨识性本质上刻画的是参数到输入–输出映射是否具有**单射性**。
$$
\theta \;\mapsto\; y(\cdot;\theta)
$$

### 2.2 闭环情形下的反直觉现象

在闭环系统中，一个常见但反直觉的现象是：

> **闭环控制往往增强了系统的可观性，却削弱了参数的可辨识性。**

在闭环系统中，控制输入通常依赖于状态与参数估计，例如
$$
u(t) = \pi(x(t), \hat{\theta}),
$$
此时输出对参数的灵敏度可以写为
$$
\frac{d y}{d \theta}
=
\frac{\partial h}{\partial x}
\frac{\partial x}{\partial \theta}
+
\frac{\partial h}{\partial \theta}.
$$

高性能控制器的设计目标是抑制状态偏差，使系统对参数扰动不敏感，即
$$
\frac{\partial x}{\partial \theta} \approx 0.
$$
这意味着，闭环控制在提升状态稳定性与可观性的同时，往往**主动削弱了输出对参数变化的响应能力**。

这一机制是自适应控制、闭环系统辨识以及参数学习中“可辨识参数子空间缩小”现象的根本原因之一。

### 2.3 Fisher 信息矩阵 / Hessian 视角

从优化与统计的角度看，可辨识性并不由一阶梯度本身决定，而是由损失函数对参数扰动的**二阶敏感性结构**所刻画。以最小二乘或极大似然问题为例，其核心信息由 Fisher 信息矩阵或损失函数的 Hessian 给出。

$$
J(\theta)
=
\frac{1}{2}
\sum_{k=1}^{N}
\| y_k^{\text{meas}} - y_k(\theta) \|^2.
$$

其梯度为：
$$
\nabla_\theta J
=
-
\sum_k
\left(
\frac{\partial y_k}{\partial \theta}
\right)^\top
e_k
$$
此时梯度依赖于误差，而不是系统本身。梯度不变有三种可能：

1. 参数的确不可辨识；
2. 在最优点附近
3. 误差被控制器压缩了

因此梯度为0并不代表没有**信息**，对损失函数做二阶泰勒展开：
$$
J(\theta + \delta\theta) \sim J(\theta) + J^T\delta\theta + \frac{1}{2}{\delta\theta^T H(\theta) \delta\theta}
$$

在高斯噪声且模型匹配的理想条件下，该 Hessian 的主导项即 Fisher 信息矩阵
$$
\mathcal{I}(\theta)
=
\mathbb{E}
\left[
\left(
\frac{\partial y}{\partial \theta}
\right)^\top
\left(
\frac{\partial y}{\partial \theta}
\right)
\right].
$$

若存在非零向量 $v$ 使得
$$
\mathcal{I}(\theta) v = 0
\quad (\text{或 } H(\theta)v \approx 0),
$$
等价于


$$
\frac{\partial y_k}{\partial \theta} \cdot v = 0, \quad \forall k
$$

则沿 $v$ 方向的参数扰动不会在二阶意义上改变损失函数，**参数沿v方向变化，输出完全不变**

因此可以得到如下结论：

- Hessian（或 Fisher 信息矩阵）的秩刻画了在当前工作点附近，哪些参数方向在**结构**上能够被数据感知；
- 其零空间对应于局部不可辨识子空间或参数等价流形的切空间；
- 对应于零特征值或近零特征值的方向，参数变化不会显著影响损失函数。
- 梯度描述的是优化动态，而 Hessian 描述的是信息与几何结构，两者在角色上并不等价。

- 实际问题中的可辨识性通常是**局部的、工作点相关的、闭环相关的**，而非全局静态性质。

## 3. 零空间与等价流形

### 3.1 零空间的数学定义

#### 线性映射下的零空间

设 $V, W$ 为有限维实向量空间，给定线性映射
$$
L : V \rightarrow W.
$$
其**零空间（null space）**定义为
$$
\mathcal{N}(L)
=
\{ v \in V \mid L(v) = 0 \}.
$$

零空间是 $V$ 的一个线性子空间，其维数称为映射 $L$ 的**零度（nullity）**。根据秩–零度定理，有
$$
\dim V = \operatorname{rank}(L) + \dim \mathcal{N}(L).
$$

零空间刻画了在映射 $L$ 作用下被“完全消除”的方向。

#### 非线性映射与局部零空间

对于一般的非线性映射
$$
F : \mathbb{R}^p \rightarrow \mathbb{R}^m,
$$
在点 $\theta$ 处，其一阶局部行为由 Jacobian 矩阵刻画
$$
J_F(\theta) = \frac{\partial F}{\partial \theta}(\theta)
$$
此时，**局部零空间**定义为该 Jacobian 的零空间：
$$
\mathcal{N}_\theta(F)
=
\{ v \in \mathbb{R}^p \mid J_F(\theta) v = 0 \}.
$$

该定义描述的是：在点 $\theta$ 附近，沿方向 $v$ 的一阶扰动不会引起映射 $F$ 的变化。

#### 几何解释

从几何角度看，零空间具有如下含义：

- 零空间中的方向对应于“不可区分方向”；
- 沿零空间方向的无穷小扰动在一阶近似下是不可观测的；
- 零空间是映射在当前点处的“退化方向集合”。

### 3.2 等价参数流形（Equivalence manifold）

若目标函数在零空间方向上保持不变，则最优解不再是孤立点，而是形成一族解的集合。形式上，若 $\theta^\star$ 为某一最优解，则对任意 $v \in \mathcal{N}(\theta^\star)$，都有
$$
J(\theta^\star + \alpha v) = J(\theta^\star), \quad \forall \alpha \in \mathbb{R},
$$
至少在局部意义下成立。

此时，最优解集合不再是单点，而是一个低维子集，通常称为**退化解（degenerate solutions）**。退化解反映的是参数在某些方向上的不可唯一性，而非优化未收敛或算法失败。

进一步地，可以将上述退化解集合理解为参数空间中的一个**等价流形（equivalence manifold）**。定义参数等价关系：
$$
\theta_1 \sim \theta_2
\quad \Longleftrightarrow \quad
y(\cdot;\theta_1) = y(\cdot;\theta_2),
$$
则所有与 $\theta$ 等价的参数构成其等价类
$$
[\theta] := \{ \theta' \mid \theta' \sim \theta \}.
$$

在局部条件下，该等价类通常可以被视为一个嵌入在参数空间中的低维流形，其切空间正由零空间 $\mathcal{N}(\theta)$ 张成：
$$
T_\theta [\theta] = \mathcal{N}(\theta).
$$

因此，零空间可以被解释为**等价流形在当前点的切空间**。

## 4. 零空间退化的主要来源

### 4.1 激励不足（Insufficient excitation）

考虑输出映射
$$
F(\theta) = y(\cdot; \theta),
$$
其局部零空间由 Jacobian的零空间决定。
$$
J_F(\theta) = \frac{\partial y}{\partial \theta}
$$
若输入信号 $u(t)$ 的激励不充分，则 Jacobian 的列空间无法覆盖整个参数空间，导致
$$
\operatorname{rank}\!\left( \frac{\partial y}{\partial \theta} \right) < p,
$$
从而产生非平凡零空间（只有零向量满足）
$$
\mathcal{N}_\theta(F) \neq \{0\}.
$$

在最小二乘意义下，这等价于 Fisher 信息矩阵退化。

物理与几何解释：

- 输入–状态–输出轨迹未覆盖系统的全部动态模式；
- 不同参数在当前激励下诱导相同或近似的输出行为；
- 参数空间中存在方向对实验“不可区分”。

这是一种**实验设计层面的不可辨识性**，即使模型结构完全正确，也无法通过现有数据消除零空间。

### 4.2 线性化不一致（Linearization mismatch）

对于非线性系统，参数灵敏度与可辨识性本质上是**局部性质**。若在不同工作点 $\theta_k$ 处进行线性化，则得到的 Jacobian，本身就是随时间变化的。
$$
J_F(\theta_k)
$$
在实际算法中，常见做法包括：

- 滑动窗口线性化；
- 在线递推更新 surrogate 模型；
- 交替优化参数与控制器。

这些都会引入**线性化不一致问题**。

![img](./res/nullspace_view.png)

不同线性化点对应的零空间
$$
\mathcal{N}_{\theta_k}(F)
$$
可能并不一致，甚至在不同时间步上维数发生变化。这会导致：

- 人为制造零空间（假不可辨识）；
- 或破坏真实等价结构（假可辨识）。

从几何角度看，这是用一系列不一致的局部切空间去近似同一个非线性流形，必然引入结构性误差。

### 4.3 参数化不合理（Structural redundancy）

即使在激励充分、线性化一致的理想条件下，零空间仍可能存在，其根源在于**模型参数化本身**。

设模型输出仅依赖于参数的某个低维映射
$$
y = h(x, u, \phi(\theta)),
$$
其中
$$
\phi : \mathbb{R}^p \rightarrow \mathbb{R}^q, \quad q < p.
$$

则对任意满足
$$
\frac{\partial \phi}{\partial \theta} v = 0
$$
的方向 $v$，都有
$$
\frac{\partial y}{\partial \theta} v = 0,
$$
从而产生**结构性零空间**，其典型表现为：

- 参数成比例出现；
- 多个参数仅通过乘积或线性组合进入模型；
- 神经网络中存在等价重参数化。

这类零空间是**模型层面固有的**，无法通过增加数据或激励消除。

注意与此处的参数化要与前面闭环控制器区分，控制器的引入并没有让参数在模型中失效，而是让系统在闭环运行时对这些参数“不再敏感”。

### 4.4 小结

但是上述三类零空间退化并不必然导致参数漂移。它们描述的是：

- 在固定目标函数与固定信息结构下；
- 参数最优解集合的几何形状。

真正导致**参数持续变化、震荡或无界增长**的原因，将在后面讨论，其核心在于**目标函数与优化结构的时变性。**

这标志着问题从“几何结构不可辨识”过渡到“动态优化不稳定”，也是参数漂移问题的本质所在。
