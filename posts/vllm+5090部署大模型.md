---
description: 自定义构建vllm镜像，并解决环境依赖问题.
date: '2025-04-23'
author: 'pxx'
categories:
  - Linux
  - LLM
  - CUDA
published: true
---

# vllm+5090部署大模型应用

> 实验室的大模型项目中，甲方提供的服务器使用了5090D显卡，给vllm的部署带来了许多麻烦

## CUDA 计算能力不匹配
vLLM 提供了一个官方 Docker 镜像用于[部署](https://vllm.hyper.ai/docs/serving/deploying-with-docker/)，但是目前最新的镜像在运行时会出现以下报错：
```bash
NVIDIA GeForce RTX 5090 with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
If you want to use the NVIDIA GeForce RTX 5090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
RuntimeError: CUDA error: no kernel image is available for execution on the device
```

原因是镜像中CUDA计算能力不匹配​​：
RTX 5090的架构（假设为Blackwell或更新架构）需要CUDA计算能力sm_120当前PyTorch版本仅支持到sm_90。可以使用以下方法查看显卡的计算能力：

**方法一：官方文档对照表**

访问NVIDIA官方文档：
https://developer.nvidia.com/cuda-gpus


输入设备显卡型号（如RTX 4090），会显示对应的​​Compute Capability​​（如8.9）。

**方法二：使用CUDA代码检测**

```python
import torch
print(torch.cuda.get_device_capability())  # 输出例如 (8, 9) 表示sm_89
```
## 从源码构建vllm镜像

参考：https://github.com/vllm-project/vllm/issues/15531

基于github上的issue，我构建了一个简单的镜像

```dockerfile
FROM m.daocloud.io/nvcr.io/nvidia/pytorch:25.02-py3

WORKDIR /workspace

RUN apt-get update && apt-get install -y --no-install-recommends \
kmod \
git \
python3-pip \
ccache \
&& apt-get clean && rm -rf /var/lib/apt/lists/*

RUN git clone https://github.com/vllm-project/vllm.git /vllm && cd /vllm


WORKDIR /vllm
RUN python use_existing_torch.py

RUN --mount=type=cache,target=/root/.cache/uv \
    pip install -r requirements/build.txt
RUN pip install setuptools_scm

RUN mkdir /ccache

ENV CCACHE_DIR=/ccache

# 设置 MAX_JOBS 以根据 CPU 核心数优化构建过程
ARG MAX_JOBS=8
RUN --mount=type=cache,target=/root/.cache/uv \
    export CMAKE_BUILD_TYPE=Release && \
    MAX_JOBS=${MAX_JOBS} CCACHE_DIR=${CCACHE_DIR} python setup.py bdist_wheel --dist-dir=dist --py-limited-api=cp38

RUN python -c "import vllm; print(vllm.__version__)"

EXPOSE 8000

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
```

vllm的编译构建时间比较长，也非常占用系统的资源，但是结果是比较好的，vllm能正常在5090显卡上运行起来了，但是构建出来的镜像非常非常的大（大概接近40G）。

## 分步构建镜像

查看了vllm的github仓库后，看到官方采用的是分布构建方案，最终的镜像中不包含中间编译文件，因此得到的镜像比较小（20G出头），最终魔改官方的Dockerfile如下：

```dockerfile
# The vLLM Dockerfile is used to construct vLLM image that can be directly used
# to run the OpenAI compatible server.

# Please update any changes made here to
# docs/source/contributing/dockerfile/dockerfile.md and
# docs/source/assets/contributing/dockerfile-stages-dependency.png

# ARG CUDA_VERSION=12.4.1
#################### BASE BUILD IMAGE ####################
# prepare basic build environment
FROM m.daocloud.io/nvcr.io/nvidia/pytorch:25.02-py3 AS base

# Install Python and other dependencies
RUN apt-get update -y \
    && apt-get install -y ccache software-properties-common git curl sudo kmod python3-pip python3-venv

# Install uv for faster pip installs
RUN --mount=type=cache,target=/root/.cache/uv \
    python3 -m pip install uv setuptools_scm -i https://pypi.tuna.tsinghua.edu.cn/simple

# This timeout (in seconds) is necessary when installing some dependencies via uv since it's likely to time out
# Reference: https://github.com/astral-sh/uv/pull/1694
ENV UV_HTTP_TIMEOUT=500

# Upgrade to GCC 10 to avoid https://gcc.gnu.org/bugzilla/show_bug.cgi?id=92519
# as it was causing spam when compiling the CUTLASS kernels
RUN apt-get install -y gcc-10 g++-10
RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-10 110 --slave /usr/bin/g++ g++ /usr/bin/g++-10
RUN <<EOF
gcc --version
EOF

# Workaround for https://github.com/openai/triton/issues/2507 and
# https://github.com/pytorch/pytorch/issues/107960 -- hopefully
# this won't be needed for future versions of this docker image
# or future versions of triton.
# RUN ldconfig /usr/local/cuda-$(echo $CUDA_VERSION | cut -d. -f1,2)/compat/

#################### BASE BUILD IMAGE ####################

#################### WHEEL BUILD IMAGE ####################
FROM base AS build

RUN git clone https://github.com/vllm-project/vllm.git /vllm
WORKDIR /vllm
RUN python use_existing_torch.py

# cuda arch list used by torch
# can be useful for both `dev` and `test`
# explicitly set the list to avoid issues with torch 2.2
# see https://github.com/pytorch/pytorch/pull/123243
# ARG torch_cuda_arch_list='7.0 7.5 8.0 8.6 8.9 9.0+PTX'
ARG torch_cuda_arch_list='12.0+PTX'
ENV TORCH_CUDA_ARCH_LIST=${torch_cuda_arch_list}
# Override the arch list for flash-attn to reduce the binary size
# ARG vllm_fa_cmake_gpu_arches='80-real;90-real'
ARG vllm_fa_cmake_gpu_arches='120-real'
ENV VLLM_FA_CMAKE_GPU_ARCHES=${vllm_fa_cmake_gpu_arches}

# This timeout (in seconds) is necessary when installing some dependencies via uv since it's likely to time out
# Reference: https://github.com/astral-sh/uv/pull/1694
ENV UV_HTTP_TIMEOUT=500

RUN --mount=type=cache,target=/root/.cache/uv \
    rm /usr/lib/python3.12/EXTERNALLY-MANAGED && \
    uv pip install --system -r requirements/build.txt
    # pip install -r requirements/build.txt

# max jobs used by Ninja to build extensions
ARG max_jobs=24
ENV MAX_JOBS=${max_jobs}
# number of threads used by nvcc
# ARG nvcc_threads=8
# ENV NVCC_THREADS=$nvcc_threads

ARG USE_SCCACHE
ARG SCCACHE_BUCKET_NAME=vllm-build-sccache
ARG SCCACHE_REGION_NAME=us-west-2
ARG SCCACHE_S3_NO_CREDENTIALS=0
# if USE_SCCACHE is set, use sccache to speed up compilation
RUN --mount=type=cache,target=/root/.cache/uv \
    # --mount=type=bind,source=.git,target=.git \
    if [ "$USE_SCCACHE" = "1" ]; then \
        echo "Installing sccache..." \
        && curl -L -o sccache.tar.gz https://github.com/mozilla/sccache/releases/download/v0.8.1/sccache-v0.8.1-x86_64-unknown-linux-musl.tar.gz \
        && tar -xzf sccache.tar.gz \
        && sudo mv sccache-v0.8.1-x86_64-unknown-linux-musl/sccache /usr/bin/sccache \
        && rm -rf sccache.tar.gz sccache-v0.8.1-x86_64-unknown-linux-musl \
        && export SCCACHE_BUCKET=${SCCACHE_BUCKET_NAME} \
        && export SCCACHE_REGION=${SCCACHE_REGION_NAME} \
        && export SCCACHE_S3_NO_CREDENTIALS=${SCCACHE_S3_NO_CREDENTIALS} \
        && export SCCACHE_IDLE_TIMEOUT=0 \
        && export CMAKE_BUILD_TYPE=Release \
        && sccache --show-stats \
        && python3 setup.py bdist_wheel --dist-dir=dist --py-limited-api=cp38 \
        && sccache --show-stats; \
    fi

ENV CCACHE_DIR=/root/.cache/ccache
RUN --mount=type=cache,target=/root/.cache/ccache \
    --mount=type=cache,target=/root/.cache/uv \
    # --mount=type=bind,source=.git,target=.git  \
    if [ "$USE_SCCACHE" != "1" ]; then \
        # Clean any existing CMake artifacts
        rm -rf .deps && \
        mkdir -p .deps && \
        # export CMAKE_BUILD_TYPE=Release && \
        python3 setup.py bdist_wheel --dist-dir=dist --py-limited-api=cp38; \
    fi

# sync the default value with .buildkite/check-wheel-size.py
ARG VLLM_MAX_SIZE_MB=400
ENV VLLM_MAX_SIZE_MB=$VLLM_MAX_SIZE_MB
ARG RUN_WHEEL_CHECK=true
RUN if [ "$RUN_WHEEL_CHECK" = "true" ]; then \
        python3 /vllm/.buildkite/check-wheel-size.py dist; \
    else \
        echo "Skipping wheel size check."; \
    fi
#################### EXTENSION Build IMAGE ####################

#################### vLLM installation IMAGE ####################
# image with vLLM installed
# TODO: Restore to base image after FlashInfer AOT wheel fixed
FROM m.daocloud.io/nvcr.io/nvidia/pytorch:25.02-py3 AS vllm-base

WORKDIR /vllm-workspace

# Install Python and other dependencies
RUN apt-get update -y \
    && apt-get install -y ccache software-properties-common git curl wget sudo vim python3-pip python3-venv \
    && apt-get install -y ffmpeg libsm6 libxext6 libgl1 \
    && python3 --version && python3 -m pip --version
# Install uv for faster pip installs
RUN --mount=type=cache,target=/root/.cache/uv \
    python3 -m pip install uv -i https://pypi.tuna.tsinghua.edu.cn/simple && \
    rm /usr/lib/python3.12/EXTERNALLY-MANAGED

# This timeout (in seconds) is necessary when installing some dependencies via uv since it's likely to time out
# Reference: https://github.com/astral-sh/uv/pull/1694
ENV UV_HTTP_TIMEOUT=500

# Workaround for https://github.com/openai/triton/issues/2507 and
# https://github.com/pytorch/pytorch/issues/107960 -- hopefully
# this won't be needed for future versions of this docker image
# or future versions of triton.
# RUN ldconfig /usr/local/cuda-$(echo $CUDA_VERSION | cut -d. -f1,2)/compat/

# Install vllm wheel first, so that torch etc will be installed.
RUN --mount=type=bind,from=build,src=/vllm/dist,target=/vllm-workspace/dist \
    --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system dist/*.whl --verbose

# If we need to build FlashInfer wheel before its release:
# $ export FLASHINFER_ENABLE_AOT=1
# $ # Note we remove 7.0 from the arch list compared to the list below, since FlashInfer only supports sm75+
# $ export TORCH_CUDA_ARCH_LIST='7.5 8.0 8.6 8.9 9.0+PTX'
# $ git clone https://github.com/flashinfer-ai/flashinfer.git --recursive
# $ cd flashinfer
# $ git checkout 524304395bd1d8cd7d07db083859523fcaa246a4
# $ rm -rf build
# $ python3 setup.py bdist_wheel --dist-dir=dist --verbose
# $ ls dist
# $ # upload the wheel to a public location, e.g. https://wheels.vllm.ai/flashinfer/524304395bd1d8cd7d07db083859523fcaa246a4/flashinfer_python-0.2.1.post1+cu124torch2.5-cp38-abi3-linux_x86_64.whl

RUN git clone https://github.com/vllm-project/vllm.git /vllm
WORKDIR /vllm
RUN python use_existing_torch.py

# Although we build Flashinfer with AOT mode, there's still
# some issues w.r.t. JIT compilation. Therefore we need to
# install build dependencies for JIT compilation.
# TODO: Remove this once FlashInfer AOT wheel is fixed
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system -r requirements/build.txt -i https://pypi.tuna.tsinghua.edu.cn/simple && \
    rm -rf /vllm

WORKDIR /vllm-workspace

#################### vLLM installation IMAGE ####################

#################### OPENAI API SERVER ####################
# base openai image with additional requirements, for any subsequent openai-style images
FROM vllm-base AS vllm-openai-base

# This timeout (in seconds) is necessary when installing some dependencies via uv since it's likely to time out
# Reference: https://github.com/astral-sh/uv/pull/1694
ENV UV_HTTP_TIMEOUT=500

# install additional dependencies for openai api server
RUN --mount=type=cache,target=/root/.cache/uv \
    if [ "$TARGETPLATFORM" = "linux/arm64" ]; then \
        uv pip install --system accelerate hf_transfer 'modelscope!=1.15.0' 'bitsandbytes>=0.42.0' 'timm==0.9.10' boto3 runai-model-streamer runai-model-streamer[s3]; \
    else \
        uv pip install --system accelerate hf_transfer 'modelscope!=1.15.0' 'bitsandbytes>=0.45.3' 'timm==0.9.10' boto3 runai-model-streamer runai-model-streamer[s3] -i https://pypi.tuna.tsinghua.edu.cn/simple; \
    fi

ENV VLLM_USAGE_SOURCE production-docker-image

FROM vllm-openai-base AS vllm-openai

RUN python -c "import vllm; print(vllm.__version__)"

ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
#################### OPENAI API SERVER ####################%  
```

使用这种构建方法得到的镜像总算是比较小了：
```bash
REPOSITORY        TAG       IMAGE ID       CREATED       SIZE
lab617_llm_vllm  latest    34b1d7f153d8   3 weeks ago   28.4GB
```

## NCCL库初始化失败
> 参考：
> 
> [vllm参数一览](https://docs.vllm.ai/en/v0.8.4_a/serving/engine_args.html)
> 
> https://huo.zai.meng.li/p/vllm%E5%90%AF%E5%8A%A8%E6%97%B6nccl%E9%81%87%E5%88%B0%E6%98%BE%E5%8D%A1p2p%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/

> 

在多卡部署的时候出现了以下错误
```bash
vllm_server3  | (VllmWorker rank=1 pid=200) INFO 04-23 08:44:33 [utils.py:931] Found nccl from library libnccl.so.2
vllm_server3  | (VllmWorker rank=0 pid=188) INFO 04-23 08:44:33 [utils.py:931] Found nccl from library libnccl.so.2
vllm_server3  | (VllmWorker rank=1 pid=200) INFO 04-23 08:44:33 [pynccl.py:69] vLLM is using nccl==2.25.1
vllm_server3  | (VllmWorker rank=0 pid=188) INFO 04-23 08:44:33 [pynccl.py:69] vLLM is using nccl==2.25.1
vllm_server3  | (VllmWorker rank=1 pid=200) Process ForkProcess-1:2:
vllm_server3  | (VllmWorker rank=0 pid=188) Process ForkProcess-1:1:
vllm_server3  | CRITICAL 04-23 08:44:34 [multiproc_executor.py:49] MulitprocExecutor got fatal signal from worker processes, shutting down. See stack trace above for root cause issue.
vllm_server3  | (VllmWorker rank=0 pid=188) Traceback (most recent call last):
vllm_server3  | (VllmWorker rank=1 pid=200) Traceback (most recent call last):
vllm_server3  | CRITICAL 04-23 08:44:34 [core_client.py:269] Got fatal signal from worker processes, shutting down. See stack trace above for root cause issue.
```

​vLLM 多进程工作线程（Worker）在启动时崩溃了​​，通常是由于 ​​NCCL 通信问题​​、​​CUDA 版本不匹配​​ 或 ​​GPU 内存不足​​导致的。NCCL（NVIDIA Collective Communications Library）是NVIDIA发布的一个高效的集体通信库，专为多个GPU之间提供优化的传输效率和简化应用而设计。

[NCCL CUDA版本对应关系](https://docs.nvidia.com/deeplearning/nccl/release-notes/index.html)
这里我怀疑是nccl库的版本没有跟上导致出现的问题，镜像中的CUDA版本为：
```bash
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Wed_Jan_15_19:20:09_PST_2025
Cuda compilation tools, release 12.8, V12.8.61
Build cuda_12.8.r12.8/compiler.35404655_0
```
使用以下环境变量帮助调试：
```bash
export NCCL_DEBUG=TRACE
export NCCL_DEBUG_FILE=/tmp/nccl-debug.log 
```
打印日志文件如下：
```bash
5e5e5d5e5412:200:200 [1] NCCL INFO cudaDriverVersion 12080
5e5e5d5e5412:200:200 [1] NCCL INFO Bootstrap: Using eth0:172.19.0.2<0>
5e5e5d5e5412:200:200 [1] NCCL INFO NCCL version 2.25.1+cuda12.8
5e5e5d5e5412:200:200 [1] NCCL INFO ncclMaxSharedMem 82240 exceeds device/fn maxSharedMem 79856
5e5e5d5e5412:200:200 [1] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v9 (v9)
5e5e5d5e5412:200:200 [1] NCCL INFO NET/Plugin: Loaded collnet plugin SHARP (v9)
5e5e5d5e5412:200:200 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
5e5e5d5e5412:200:200 [1] NCCL INFO P2P plugin v9 IBext_v9
5e5e5d5e5412:200:200 [1] NCCL INFO NET/IB : No device found.
5e5e5d5e5412:200:200 [1] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.19.0.2<0>
5e5e5d5e5412:200:200 [1] NCCL INFO NET/IB : No device found.
5e5e5d5e5412:200:200 [1] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.19.0.2<0>
5e5e5d5e5412:200:200 [1] NCCL INFO NET/Socket : Using [0]eth0:172.19.0.2<0>
5e5e5d5e5412:200:200 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.
5e5e5d5e5412:200:200 [1] NCCL INFO Using network Socket
5e5e5d5e5412:200:200 [1] NCCL INFO ncclCommInitRank comm 0x2e72a130 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 7000 commId 0x78d72067324f0bd9 - Init START
5e5e5d5e5412:188:188 [0] NCCL INFO RAS client listening socket at ::1<28028>
5e5e5d5e5412:188:188 [0] NCCL INFO Bootstrap timings total 0.026179 (create 0.000014, send 0.000071, recv 0.025896, ring 0.000011, delay 0.000000)
5e5e5d5e5412:200:200 [1] NCCL INFO NCCL_CUMEM_ENABLE set by environment to 0.

5e5e5d5e5412:200:200 [1] graph/search.cc:1135 NCCL WARN Could not find a path for pattern 4, falling back to simple order

5e5e5d5e5412:200:200 [1] graph/search.cc:1135 NCCL WARN Could not find a path for pattern 1, falling back to simple order
5e5e5d5e5412:188:188 [0] NCCL INFO comm 0x2e820590 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
5e5e5d5e5412:200:200 [1] NCCL INFO Trees [0] -1/-1/-1->5e5e5d5e5412:188:188 [0]5e5e5d5e5412:200:200 [1] NCCL I5e5e5d5e5412:188:188 [0] NCCL IN5e5e5d5e5412:200:246 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
5e5e5d5e5412:200:244 [1] NCCL INFO [Proxy Service] Device 1 CPU core 6
5e5e5d5e5412:200:200 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct
5e5e5d5e5412:200:200 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct
5e5e5d5e5412:200:200 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
5e5e5d5e5412:200:200 [1] NCCL INFO Connected all trees
5e5e5d5e5412:200:249 [1] NCCL INFO [Proxy Progress] Device 1 CPU core 12
5e5e5d5e5412:200:200 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
5e5e5d5e5412:200:200 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p ch5e5e5d5e5412:1885e5e5d5e5412:200:200 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v4 symbol.
5e5e5d5e5412:200:200 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
5e5e5d5e5412:200:200 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
5e5e5d5e5412:200:200 [1] NCCL INFO ncclCommInitRank comm 0x2e72a130 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 7000 commId 0x78d72067324f0bd9 - Init COMPLETE
5e5e5d5e5412:200:200 [1] NCCL INFO Init timings - ncclCommInitRank: rank 1 nranks 2 total 0.14 (kernels 0.12, alloc 0.00, bootstrap 0.00, allgathers 0.00, topo 0.00, graphs 0.00, connections 0.02, rest 0.00)

5e5e5d5e5412:200:200 [1] enqueue.cc:1500 NCCL WARN Cuda failure 1 'invalid argument'
5e5e5d5e5412:200:200 [1] NCCL INFO group.cc:242 -> 1
5e5e5d5e5412:200:200 [1] NCCL INFO group.cc:470 -> 1
5e5e5d5e5412:200:200 [1] NCCL INFO group.cc:573 -> 1
5e5e5d5e5412:200:200 [1] NCCL INFO enqueue.cc:2229 -> 1
NCCL WARN Cuda failure 1 'invalid argument'
5e5e5d5e5412:188:188 [0] NCCL INFO group.cc:242 -> 1
5e5e5d5e5412:188:188 [0] NCCL INFO group.cc:470 -> 1
5e5e5d5e5412:188:188 [0] NCCL INFO group.cc:573 -> 1
5e5e5d5e5412:188:188 [0] NCCL INFO enqueue.cc:2229 -> 1

```
`5e5e5d5e5412:200:200 [1] enqueue.cc:1500 NCCL WARN Cuda failure 1 'invalid argument'`表明在调用CUDA内核的时候传入了非法操作。

## NCCL-tests
[NCCL Tests](https://github.com/NVIDIA/nccl-tests) 是官方提供的一套工具，用于验证NCCL安装和通信是否正常

执行以下命令查看单显卡：
```bash
./build/all_reduce_perf -b 8 -e 128M -f 2 -g 1

# nThread 1 nGpus 1 minBytes 8 maxBytes 134217728 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0
#
# Using devices
#  Rank  0 Group  0 Pid   5736 on 04d90d6edf3b device  0 [0000:01:00] NVIDIA GeForce RTX 5090 D
#
#                                                              out-of-place                       in-place          
#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong
#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
           8             2     float     sum      -1     5.51    0.00    0.00      0     0.06    0.15    0.00      0
          16             4     float     sum      -1     5.64    0.00    0.00      0     0.06    0.28    0.00      0
          32             8     float     sum      -1     5.67    0.01    0.00      0     0.05    0.58    0.00      0
          64            16     float     sum      -1     5.68    0.01    0.00      0     0.06    1.16    0.00      0
         128            32     float     sum      -1     5.96    0.02    0.00      0     0.05    2.34    0.00      0
         256            64     float     sum      -1     5.73    0.04    0.00      0     0.06    4.60    0.00      0
         512           128     float     sum      -1     5.68    0.09    0.00      0     0.06    9.22    0.00      0
        1024           256     float     sum      -1     5.67    0.18    0.00      0     0.05   18.64    0.00      0
        2048           512     float     sum      -1     6.12    0.33    0.00      0     0.06   37.10    0.00      0
        4096          1024     float     sum      -1     6.39    0.64    0.00      0     0.05   74.61    0.00      0
        8192          2048     float     sum      -1     5.77    1.42    0.00      0     0.05  149.49    0.00      0
       16384          4096     float     sum      -1     5.79    2.83    0.00      0     0.06  296.54    0.00      0
       32768          8192     float     sum      -1    12.19    2.69    0.00      0     0.06  588.29    0.00      0
       65536         16384     float     sum      -1     5.80   11.30    0.00      0     0.06  1179.77    0.00      0
      131072         32768     float     sum      -1     5.81   22.56    0.00      0     0.05  2396.20    0.00      0
      262144         65536     float     sum      -1    20.78   12.61    0.00      0     0.05  4779.29    0.00      0
      524288        131072     float     sum      -1     5.88   89.22    0.00      0     0.06  9387.43    0.00      0
     1048576        262144     float     sum      -1     7.55  138.83    0.00      0     0.06  18331.75    0.00      0
     2097152        524288     float     sum      -1     7.77  269.89    0.00      0     0.06  38026.33    0.00      0
     4194304       1048576     float     sum      -1     8.93  469.64    0.00      0     0.06  75166.74    0.00      0
     8388608       2097152     float     sum      -1    11.83  709.13    0.00      0     0.06  152520.15    0.00      0
    16777216       4194304     float     sum      -1    27.73  605.00    0.00      0     0.05  306153.58    0.00      0
    33554432       8388608     float     sum      -1    43.24  776.03    0.00      0     0.06  600258.18    0.00      0
    67108864      16777216     float     sum      -1    88.15  761.29    0.00      0     0.06  1195171.22    0.00      0
   134217728      33554432     float     sum      -1    211.6  634.22    0.00      0     0.06  2390342.44    0.00      0
# Out of bounds values : 0 OK
# Avg bus bandwidth    : 0 

```
参数说明：
- -b 8: 起始数据量(Byte)
- -e 512M: 最大数据量
- -f 2: 步长因子(以2倍增长)
- -g 2: 使用两个gpu

但是查看双显卡的时候：
```bash
# nThread 1 nGpus 2 minBytes 8 maxBytes 134217728 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0
#
# Using devices
#  Rank  0 Group  0 Pid   5748 on 04d90d6edf3b device  0 [0000:01:00] NVIDIA GeForce RTX 5090 D
#  Rank  1 Group  0 Pid   5748 on 04d90d6edf3b device  1 [0000:07:00] NVIDIA GeForce RTX 5090 D
#
#                                                              out-of-place                       in-place          
#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong
#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
04d90d6edf3b: Test NCCL failure common.cu:409 'unhandled cuda error (run with NCCL_DEBUG=INFO for details) / '
 .. 04d90d6edf3b pid 5748: Test failure common.cu:607
 .. 04d90d6edf3b pid 5748: Test failure all_reduce.cu:90
 .. 04d90d6edf3b pid 5748: Test failure common.cu:640
 .. 04d90d6edf3b pid 5748: Test failure common.cu:1170
 .. 04d90d6edf3b pid 5748: Test failure common.cu:915
```

## 升级最新的NCCL

https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt install libnccl2 libnccl-dev # 不加这一行依旧使用旧版本的NCCL
```

查看拓扑
```bash
nvidia-smi topo -m

	GPU0	GPU1	CPU Affinity	NUMA Affinity	GPU NUMA ID
GPU0	 X 	PHB	0-31	0		N/A
GPU1	PHB	 X 	0-31	0		N/A

```

接下来使用`nccl-tests`测试的时候非常慢，这是因为NCCL性能非常依赖GPU之间的互联方式。如果GPU不在同一个PCIe Root Complex(或者没有NVLink)，速度就会慢很多。`PHB`表示两张卡通过PCIe Host Bridge连接(最慢)



最后总算是成功了，vllm现在也可以多卡推理了。